{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First of all importing  important packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wrangling include this 3 steps \n",
    "- Gathering \n",
    "- Assessing \n",
    "- Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather\n",
    "### we have got 3 kinds of data to gather to gather in 3 ways \n",
    "- twitter_archive.csv\n",
    "- image_prediction.tsv \n",
    "- twitter APIs in json formated .txt  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First is twitter_archive.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this data part in on hand twitter_archive.csv\n",
    "twitter_archive = pd.read_csv('twitter-archive-enhanced-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-31 00:18:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891815181...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Archie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-30 15:58:51 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Darla. She commenced a snooze mid meal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891689557...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Darla</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "2  891815181378084864                    NaN                  NaN   \n",
       "3  891689557279858688                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "2  2017-07-31 00:18:03 +0000   \n",
       "3  2017-07-30 15:58:51 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...                  NaN   \n",
       "3  This is Darla. She commenced a snooze mid meal...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "2  https://twitter.com/dog_rates/status/891815181...                12   \n",
       "3  https://twitter.com/dog_rates/status/891689557...                13   \n",
       "\n",
       "   rating_denominator     name doggo floofer pupper puppo  \n",
       "0                  10  Phineas  None    None   None  None  \n",
       "1                  10    Tilly  None    None   None  None  \n",
       "2                  10   Archie  None    None   None  None  \n",
       "3                  10    Darla  None    None   None  None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploer twitter_archive\n",
    "twitter_archive.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second is image_prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the folder with same name doesnt exist and if yes make a new folder named (image_predictions)\n",
    "folder_name = 'image_predictions'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the image_prediction file from udacity server\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "response [200] means the request has succeeded \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will write image prediction data to a file in our folder image_predictions\n",
    "with open(os.path.join(folder_name, url.split('/')[-1]), mode='wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "os.listdir(folder_name)\n",
    "image_predictions_df = pd.read_csv('image_predictions/image-predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploer df_image_prediction\n",
    "image_predictions_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Third is twitter API  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Authentication part to get the data from twitter API \n",
    "# consumer_key = 'HIDDEN'\n",
    "# consumer_secret = 'HIDDEN'\n",
    "# access_token = 'HIDDEN'\n",
    "# access_secret = 'HIDDEN'\n",
    "\n",
    "# auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "# auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "# api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# # that part is tweets id's allow us to get the tweets infos from twitter API\n",
    "\n",
    "# tweet_ids = twitter_archive.tweet_id.values\n",
    "# len(tweet_ids)\n",
    "\n",
    "# # Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "# count = 0\n",
    "# fails_dict = {} # fail id's will be saved here (the id's which tweets either deleted or accounts were removed)\n",
    "# start = timer()\n",
    "\n",
    "# # Save each tweet's returned JSON as a new line in a .txt file\n",
    "# with open('tweet_json.txt', 'w') as json_file:\n",
    "#     # This loop will likely take 20-30 minutes to run because of Twitter's rate limit (it will get tweets infos from the api and if TweepError exception happend it wont break the loop cuz except statement then the fail id will be saved in the dict above)\n",
    "#     for tweet_id in tweet_ids:\n",
    "#         count += 1\n",
    "#         print(str(count) + \": \" + str(tweet_id))\n",
    "#         try:\n",
    "#             tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "#             print(\"Success\")\n",
    "#             json.dump(tweet._json, json_file) # to write the data which from twitter api in the txt file\n",
    "#             json_file.write('\\n')\n",
    "#         except tweepy.TweepError as e:\n",
    "#             print(\"Fail\")\n",
    "#             fails_dict[tweet_id] = e\n",
    "#             pass\n",
    "# end = timer()\n",
    "# print(end - start)\n",
    "# print(fails_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_status = pd.read_json(r'we_rate_dogs\\tweet-json', lines = True,encoding='utf-8')\n",
    "\n",
    "tweets_data = []\n",
    "with open('tweet-json') as tweet_status:        \n",
    "    for json_obj in tweet_status:\n",
    "        df_tweet_min = collections.OrderedDict()\n",
    "        df_tweet_full = json.loads(json_obj)\n",
    "\n",
    "        # Get all of the data we're interested in\n",
    "        df_tweet_min['tweet_id'] = df_tweet_full['id']\n",
    "        df_tweet_min['retweet_count'] = df_tweet_full['retweet_count']\n",
    "        df_tweet_min['favorite_count'] = df_tweet_full['favorite_count']\n",
    "\n",
    "        # Append it to the data gathering list\n",
    "        tweets_data.append(df_tweet_min)\n",
    "\n",
    "# Create a dataframe from the data\n",
    "tweet_api_df = pd.DataFrame(tweets_data)\n",
    "tweet_api_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The data has now been loaded into the following DFs:\n",
    "\n",
    "- twitter_archive.csv as twitter_archive\n",
    "- image_prediction.tsv as df_image_prediction\n",
    "- twitter APIs in json formated (txt) as tweet_api_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Assessing \n",
    "### Archive DF\n",
    "i used excel to do this step\n",
    "- theres none values as string not NAN so validation issue .\n",
    "- source column has html tags which i think they aren't important and device column should show me the device and applicaton used if it web , vine or phone app (html tags meant to download the app for each device type) .\n",
    "- timestamp has 00:00 which is duplicated and not necessary should be deleted .\n",
    "- denominator and numerator columns has outliers (this one need to be checked with programmatically assessing to make sure) .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmatic Assessing\n",
    "### Archive\n",
    "- (in_reply_to_status_id) and (in_reply_to_user_id) columns have alot of missing data only (78) and not needed data .\n",
    "- before dropping them we need to drop the not null values to make sure our data cleaned from replies\n",
    "- (retweeted_status_id), (retweeted_status_user_id), (retweeted_status_timestamp) columns have alot of missing data only (181) also not needed data . \n",
    "- before dropping them we need to drop these tweets to make sure our data cleaned from replies and \n",
    "\n",
    "- Timestamp column with wrong data type it should be Datetime not object\n",
    "- demnoerator and numerator has different values from text i should change them manually. \n",
    "- many strange names for dogs in column 'name' like 'none', 'a', 'actually', 'O' and 'all' should be removed .\n",
    "### Image predictions file \n",
    "- we have 2075 tweets with images while we archive has 2356 that means we have 281 rows with tweet_id that either retweets or somthing else than dogs .\n",
    "- in df_image_prediction the name of columns (p1, p1_conf, p1_dog, p2, p2_conf, p2_dog, p3, p3_conf, p3_dog) as p1, p2 and p3 contain the same type of data, predictions. aren't usefull to be used for analysis or understanding the data .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tidiness issues \n",
    "- there are 4 columns for dogs types which is tidy issue so we can make one column to get them all but when i scanned the data visually with excel i saw that there are two or more types for same dog which we can separate with commas.\n",
    "- it would be easier for analysis after cleaning each Df make one table that has the three dfs (twitter_archive),(tweet_api_df), (df_image_prediction).\n",
    "- as tidy data rules (p1, p1_conf, p1_dog, p2, p2_conf, p2_dog, p3, p3_conf, p3_dog) not qualified as the columns p1, p2 and p3 contain the same type of data, predictions, The columns p1_conf, p2_conf and p3_conf all contain values for confidence level, and columns p1_dog, p2_dog and p3_dog all contain Boolean values indicating whether the prediction is in fact a type of dog, so i will melt them into 2 columns that tells us breed and confidence of the machine . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### those notes was taken after doing the assessing below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive['name'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got a problem here as all null values written as none (string) in name , and dog types columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweet_api_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_predictions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there dulpicates in DFs\n",
    "sum(tweet_api_df.duplicated()),sum(twitter_archive.duplicated()),sum(image_predictions_df.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there duplicates in tweet_id columns\n",
    "sum(tweet_api_df.duplicated('tweet_id')),sum(twitter_archive.duplicated('tweet_id')),sum(image_predictions_df.duplicated('tweet_id'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = pd.Series(list(twitter_archive) + list(tweet_api_df) + list(image_predictions_df))\n",
    "all_columns[all_columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive['rating_numerator'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['rating_denominator'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive['name'].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.value_counts('name')['actually'],twitter_archive.value_counts('name')['all'],twitter_archive.value_counts('name')['a'],twitter_archive.value_counts('name')['O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive.query('name == \"a\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive.query('rating_numerator == \"0\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive.query('rating_denominator == \"0\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df.query('tweet_id == \"835152434251116546\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df.query('tweet_id == \"746906459439529985\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not a dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df.query('tweet_id == \"835246439529840640\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][313]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_predictions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.query('rating_numerator == \"1776\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive['text'][979]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he might love his dog so much "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.query('rating_denominator == \"170\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive['text'][1120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "strange rating but still ok cuz that page is famous for it   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image prediction columns \n",
    "- p1 is the algorithm's #1 prediction for the image in the tweet \n",
    "- p1_conf is how confident the algorithm is in its #1 prediction \n",
    "- p1_dog is whether or not the #1 prediction is a breed of dog\n",
    "- p2 is the algorithm's second most likely prediction \n",
    "- p2_conf is how confident the algorithm is in its #2 prediction\n",
    "- p2_dog is whether or not the #2 prediction is a breed of dog etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_predictions_df.query('p1_conf == \"1.000000\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_api_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_api_df.query('retweet_count == \"79515\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "highest tweet got retweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive.query('tweet_id == \"744234799360020481\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1039]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df.query('tweet_id == \"744234799360020481\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_predictions_df['jpg_url'][1221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_api_df.query('retweet_count == \"624\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_predictions_df.query('tweet_id == \"681242418453299201\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the dog havent been recognized by the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive['rating_denominator'] > 11].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive['rating_numerator'] > 11].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][433]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][902]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1165]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1202]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1228]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1254]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1274]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1351]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1433]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1598]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1634]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1663]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive['text'][1779]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "twitter_archive['text'][1843]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### to make sure that all  are tweets and with images i will do another assessing after cleaning ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summery \n",
    "    Quality\n",
    "-  change 'None values' in name and dog types columns to empty string. \n",
    "-  remove html tags from source column.\n",
    "-  change Timestamp column's type to datetime.\n",
    "-  change the type of tweet_id:object, source: category, rating_numerator:float, retweet_count and favorite_count: int32 which would make it smaller as we wont use the 64 bit at all , dog_types:category\n",
    "-  drop (in_reply_to_status_id) and (in_reply_to_user_id) columns\n",
    "           before that we should drop not null values \n",
    "-  drop (retweeted_status_id), (retweeted_status_user_id), (retweeted_status_timestamp) columns\n",
    "           before that we should drop not null values \n",
    "-  change the columns names in image_predictions_df. \n",
    "-  drop duplicated columns. \n",
    "-  drop tweets arent having images.   \n",
    "-  drop null values from expanded_urls. \n",
    "-  change lower case (not names) from name column like 'a', 'actually', 'O' and 'all' to empty string and None values as well.\n",
    "- last step would be change the names of columns for the final biggest df which will be combination of the 3 dfs , that would make my analysis easier .\n",
    "    \n",
    "    tidiness\n",
    "-  append all 3 tables in one.\n",
    "-  make one column (dog_types) by appending the 4 columns (doggo) (floofer) (pupper) (puppo).\n",
    "-  The json_data table should be combined with the archive table.\n",
    "-  change all p,p_conf,p_dog into 2 columns storing breed and confidence of the breed then drop these columns (p,p_conf,p_dog) .\n",
    "-  restructure the columns which will help me in analysis .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat a copy of the original 3 datasets for reference\n",
    "archive_clean_df = twitter_archive.copy()\n",
    "image_clean_df = image_predictions_df.copy()\n",
    "json_clean_df = tweet_api_df.copy()\n",
    "archive_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "### define\n",
    "starting with cleaning the unnecessary data in (in_reply_to_status_id) and (in_reply_to_user_id) columns as we dont need replies for analysis ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df = archive_clean_df[archive_clean_df.in_reply_to_user_id.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "### define \n",
    "drop these empty columns will make my df better for analysis ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df = archive_clean_df.drop(['in_reply_to_status_id','in_reply_to_user_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "### define \n",
    "we dont need any data about retweets (retweeted_status_id), (retweeted_status_user_id), (retweeted_status_timestamp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df = archive_clean_df[archive_clean_df.retweeted_status_id.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "archive_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4\n",
    "### Define\n",
    "dropping these columns will make our df more tidy and less noisy when accessing data with or assessing again ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df = archive_clean_df.drop(['retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now i have deleted rows that related to retweets and replies which is not necessary and all we have now is tweets df ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5\n",
    "### define\n",
    "before metling the 4 dog types into one column we need to change none values into ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df['doggo'].replace(to_replace = 'None' ,value =  '', inplace=True),\n",
    "archive_clean_df['floofer'].replace(to_replace = 'None' ,value =  '', inplace=True),\n",
    "archive_clean_df['pupper'].replace(to_replace = 'None' ,value =  '', inplace=True),\n",
    "archive_clean_df['puppo'].replace(to_replace = 'None' ,value =  '', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df.value_counts(['doggo','floofer','pupper','puppo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i made it like that to be able to convert the all four columns easily and i saw while assessing that some dogs have 2 or more types that would prevent losing these compound types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6\n",
    "### define\n",
    "now for more tidyness i need to melt these columns ('doggo','floofer','puppo','pupper')  into one which is dog_types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df['dog_types'] = archive_clean_df['doggo'] + archive_clean_df['floofer'] + archive_clean_df['pupper'] + archive_clean_df['puppo'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df['expanded_urls'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df['expanded_urls'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7\n",
    "### Define\n",
    "delete null values in expanded_urls column ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df = archive_clean_df[archive_clean_df.expanded_urls.notnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8\n",
    "### Define\n",
    "for tidyness dropping 4 dog types columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df.drop(['doggo', 'pupper', 'floofer', 'puppo'], axis = 1 , inplace = True)\n",
    "archive_clean_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9\n",
    "### Define\n",
    "now merging archive_clean_df, json_clean_df ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(archive_clean_df,json_clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10\n",
    "### Define\n",
    "we can clear the timestamp from +00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.timestamp = df.timestamp.str.strip('+0000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11\n",
    "### Define\n",
    "Change timestamp type from object to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12\n",
    "### Define\n",
    "delete html tags and make it refering to the source of the tweet like phone or web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = df['source'].str.extract('^<a.+>(.+)</a>$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13\n",
    "### Define\n",
    "while i was assessing vitually i saw that the strange names for dogs are always .islower (small_character_name) so i will change it to '' like what i have done in dog_types ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_character_name = df.name.str.contains('^[a-z]')\n",
    "df.loc[small_character_name, 'name'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14\n",
    "### Define\n",
    "change none values to make it '' like the rest of NAN values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name.replace('None', '', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15\n",
    "#### Define\n",
    "in image_prediction_df i thought its not usefull to get all predictions as some are false and for every one has its confidence so i thought about making 2 columns getting in them the prediction with true value and its confidence ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2 empty lists to save our choice for each row in the dataset\n",
    "confidence = []\n",
    "breed = []\n",
    "\n",
    "# function that iterates through prediction columns to find the best prediction which is a breed of dog.\n",
    "def Breeds_and_confidence(row):\n",
    "    if row['p1_dog'] == True:\n",
    "        breed.append(row['p1'])\n",
    "        confidence.append(row['p1_conf'])\n",
    "    elif row['p2_dog'] == True:\n",
    "        breed.append(row['p2'])\n",
    "        confidence.append(row['p2_conf'])\n",
    "    elif row['p3_dog'] == True:\n",
    "        breed.append(row['p3'])\n",
    "        confidence.append(row['p3_conf'])\n",
    "    else:\n",
    "        breed.append('Unknown')\n",
    "        confidence.append(0)\n",
    "        \n",
    "# call function using pandas apply by columns\n",
    "image_clean_df.apply(Breeds_and_confidence, axis=1)\n",
    "\n",
    "# add lists created to master dataframe\n",
    "image_clean_df['Breed'] = breed\n",
    "image_clean_df['Confidence'] = confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now i took what i need for analysis in this df now i will drop the prediction columns and confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16\n",
    "### Define\n",
    "now i took what i need for analysis in this df now i will drop the prediction columns and confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_clean_df.drop(['p1','p1_conf','p2','p2_conf','p3','p3_conf','p1_dog','p2_dog','p3_dog','img_num'], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_clean_df.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_predictions_df.query('tweet_id == \"783839966405230592\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df.query('tweet_id == \"681242418453299201\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df.query('tweet_id == \"695064344191721472\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_df.query('tweet_id == \"686749460672679938\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "well 'Unkown' breed and confidence 0 is not a valid data ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17\n",
    "### Define\n",
    "now we can merge all dfs in big one called df_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df,image_clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that change because some tweets in archive didnt have images in image_prediction_df and there were images with tweet_ids are same for replies which was deleted from archive ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18\n",
    "### Define\n",
    "now lets change some types which would be more realistic ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['tweet_id'] = df_all['tweet_id'].astype(object)\n",
    "df_all['source'] = df_all['source'].astype('category')\n",
    "df_all['rating_numerator'] = df_all['rating_numerator'].astype(float)\n",
    "df_all['retweet_count'] = df_all['retweet_count'].astype(int)\n",
    "df_all['favorite_count'] = df_all['favorite_count'].astype(int)\n",
    "df_all['dog_types'] = df_all['dog_types'].astype('category')\n",
    "df_all['Confidence'] = df_all['Confidence'].round(2) # after cleaning and assessing again i can see that its numbers too long "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19\n",
    "### Define \n",
    "while assessing i found a few data in rating_denominator, rating_numerator that has different value from what in text ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all[df_all['rating_denominator'] > 11].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note. if i saw rating in the text i will change the rating to it if not i will calculate the rating from the exiting data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all['text'][320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][658]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][842]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][884]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['tweet_id'][320],df_all['tweet_id'][658],df_all['tweet_id'][842],df_all['tweet_id'][884]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_numerator'][320],df_all['rating_numerator'][658],df_all['rating_numerator'][842],df_all['rating_numerator'][884]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_denominator'][320],df_all['rating_denominator'][658],df_all['rating_denominator'][842],df_all['rating_denominator'][884]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each tweet id above\n",
    "df_all.loc[df_all.tweet_id == 820690176645140481, 'rating_numerator'] = 12 #84/70= 1.2*10 = 12\n",
    "df_all.loc[df_all.tweet_id == 820690176645140481, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 758467244762497024, 'rating_numerator'] = 11 #165/150\n",
    "df_all.loc[df_all.tweet_id == 758467244762497024, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 731156023742988288, 'rating_numerator'] = 12 #204/170= 1.2*10 = 12\n",
    "df_all.loc[df_all.tweet_id == 731156023742988288, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 722974582966214656, 'rating_numerator'] = 13 # 4/20\n",
    "df_all.loc[df_all.tweet_id == 722974582966214656, 'rating_denominator'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all['text'][918]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][939]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][963]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][981]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['tweet_id'][918],df_all['tweet_id'][939],df_all['tweet_id'][963],df_all['tweet_id'][981]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_numerator'][918],df_all['rating_numerator'][939],df_all['rating_numerator'][963],df_all['rating_numerator'][981]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_denominator'][918],df_all['rating_denominator'][939],df_all['rating_denominator'][963],df_all['rating_denominator'][981]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each tweet id above\n",
    "df_all.loc[df_all.tweet_id == 716439118184652801, 'rating_numerator'] = 11 #50/50\n",
    "df_all.loc[df_all.tweet_id == 716439118184652801, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 713900603437621249, 'rating_numerator'] = 11 #99/90\n",
    "df_all.loc[df_all.tweet_id == 713900603437621249, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 710658690886586372, 'rating_numerator'] = 10 #80/80\n",
    "df_all.loc[df_all.tweet_id == 710658690886586372, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 709198395643068416, 'rating_numerator'] = 9 # 45/50\n",
    "df_all.loc[df_all.tweet_id == 709198395643068416, 'rating_denominator'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][1045]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][1288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][1420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all['text'][1478]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['tweet_id'][1045],df_all['tweet_id'][1288],df_all['tweet_id'][1420],df_all['tweet_id'][1478]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_numerator'][1045],df_all['rating_numerator'][1288],df_all['rating_numerator'][1420],df_all['rating_numerator'][1478]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_denominator'][1045],df_all['rating_denominator'][1288],df_all['rating_denominator'][1420],df_all['rating_denominator'][1478]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each tweet id above\n",
    "df_all.loc[df_all.tweet_id == 704054845121142784, 'rating_numerator'] = 12 #60/50\n",
    "df_all.loc[df_all.tweet_id == 704054845121142784, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 684222868335505415, 'rating_numerator'] = 11 #121/110\n",
    "df_all.loc[df_all.tweet_id == 684222868335505415, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 677716515794329600, 'rating_numerator'] = 12 #144/120\n",
    "df_all.loc[df_all.tweet_id == 677716515794329600, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 675853064436391936, 'rating_numerator'] = 11 # 88/80\n",
    "df_all.loc[df_all.tweet_id == 675853064436391936, 'rating_denominator'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all['rating_numerator'] > 14].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][382]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_numerator'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as u can see theres no rating and i cant give anything for 24/7 so i will give it average rating of the df which is 11.5/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][549]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all['text'][722]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][1120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][1359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][1696]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['tweet_id'][382],df_all['tweet_id'][499],df_all['tweet_id'][549],df_all['tweet_id'][722],df_all['tweet_id'][1120],df_all['tweet_id'][1359],df_all['tweet_id'][1696]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_numerator'][382],df_all['rating_numerator'][499],df_all['rating_numerator'][549],df_all['rating_numerator'][722],df_all['rating_numerator'][1120],df_all['rating_numerator'][1359],df_all['rating_numerator'][1696]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_denominator'][382],df_all['rating_denominator'][499],df_all['rating_denominator'][549],df_all['rating_denominator'][722],df_all['rating_denominator'][1120],df_all['rating_denominator'][1359],df_all['rating_denominator'][1696]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each tweet id above\n",
    "df_all.loc[df_all.tweet_id == 810984652412424192, 'rating_numerator'] = 11.5 #24/7\n",
    "df_all.loc[df_all.tweet_id == 810984652412424192, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 786709082849828864, 'rating_numerator'] = 9.75 #75/10\n",
    "df_all.loc[df_all.tweet_id == 786709082849828864, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 778027034220126208, 'rating_numerator'] = 11.27 #27/10\n",
    "df_all.loc[df_all.tweet_id == 778027034220126208, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 749981277374128128, 'rating_numerator'] = 17.5 # 1776/10\n",
    "df_all.loc[df_all.tweet_id == 749981277374128128, 'rating_denominator'] = 10\n",
    "\n",
    "df_all.loc[df_all.tweet_id == 697463031882764288, 'rating_numerator'] = 11 #44/40\n",
    "df_all.loc[df_all.tweet_id == 697463031882764288, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 680494726643068929, 'rating_numerator'] = 11.26 #26/10\n",
    "df_all.loc[df_all.tweet_id == 680494726643068929, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 670842764863651840, 'rating_numerator'] = 14.2 #420/10\n",
    "df_all.loc[df_all.tweet_id == 670842764863651840, 'rating_denominator'] = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_numerator'] = df_all['rating_numerator'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making sure that doesnt exceed 2 digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.rating_numerator.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all[df_all['rating_denominator'] > 10].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all['rating_denominator'] < 10].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][794]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][1313]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['text'][1950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['tweet_id'][794],df_all['tweet_id'][1313],df_all['tweet_id'][1950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_numerator'][794],df_all['rating_numerator'][1313],df_all['rating_numerator'][1950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['rating_denominator'][794],df_all['rating_denominator'][1313],df_all['rating_denominator'][1950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each tweet id above\n",
    "df_all.loc[df_all.tweet_id == 740373189193256964, 'rating_numerator'] = 14 #9/11\n",
    "df_all.loc[df_all.tweet_id == 740373189193256964, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 682962037429899265, 'rating_numerator'] = 10 #7/11 that meant be the store\n",
    "df_all.loc[df_all.tweet_id == 682962037429899265, 'rating_denominator'] = 10 \n",
    "\n",
    "df_all.loc[df_all.tweet_id == 666287406224695296, 'rating_numerator'] = 9 #1/2 it meant half breed \n",
    "df_all.loc[df_all.tweet_id == 666287406224695296, 'rating_denominator'] = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 \n",
    "### Define\n",
    "- last step would be changing the names of columns and restructure them to make my analysis easier.\n",
    "- and replace breeds that are unknown .\n",
    "- as we managed to make all denominators 10 so i think it would be ok to delete it which 'Out_of' ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change their names \n",
    "df_all = df_all.rename(columns = { 'tweet_id': 'Tweet_id',\n",
    "                                   'timestamp':'Tweet_date',\n",
    "                                   'source': 'Tweet_source',\n",
    "                                   'text': 'Tweet_text',\n",
    "                                   'expanded_urls': 'Tweet_url',\n",
    "                                   'rating_numerator': 'Dog_score/10',\n",
    "                                   'rating_denominator':'Out_of',\n",
    "                                   'dog_types': 'Dog_type',\n",
    "                                   'name': 'Dog_name',\n",
    "                                   'favorite_count':'Num_of_likes',\n",
    "                                   'retweet_count' :'Retweets',\n",
    "                                   'jpg_url': 'Image_link',\n",
    "                                   'Breed': 'Dog_Breed',\n",
    "                                   'Confidence': 'Probability_AI_calc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change its structure to make the data needed for analysis easy to access \n",
    "df_all = df_all[['Tweet_id','Tweet_date','Tweet_source','Tweet_text','Dog_name',\n",
    "                 'Dog_score/10','Out_of','Dog_type','Dog_Breed','Probability_AI_calc',\n",
    "                 'Num_of_likes','Retweets','Tweet_url','Image_link']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.Dog_Breed.replace('None', '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.Dog_Breed.replace('Unknown', '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['Out_of'], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems to be fine for me now we can store it in twitter_archive_master.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all.to_csv('twitter_archive_master.csv', encoding='utf-8',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cleaned = pd.read_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cleaned.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c = df_all_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all_c.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting with getting simple statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tweets range in time\n",
    "print('we have data since {} untill {}'.format(df_all_c.Tweet_date.min(),df_all_c.Tweet_date.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i thought about getting a dog so i will try to get some information out of this data that could help me choose which breed to raise ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i like german shepherd so lets investigate \n",
    "### is there a german shephered? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all_c.query('Dog_Breed == \"German_shepherd\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df_all_c.query('Dog_Breed == \"German_shepherd\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not popular among this community only 21 tweets , its rating is ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all_c.query('Dog_Breed == \"German_shepherd\"')['Dog_score/10'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as u can see  theres 21 tweets about german sheperd i didnt expect that as i like this breed alot with avg rating 11/10 not bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which breeds are most tweeted about? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c.Dog_Breed.value_counts().nlargest(20).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "df_all_c.Dog_Breed.value_counts().nlargest(20).sort_values(ascending=False).plot.pie()\n",
    "plt.title(\"Top 20 breeds with most tweets \",fontsize=18)\n",
    "plt.ylabel(\" \")\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "df_all_c.Dog_Breed.value_counts().nlargest(20).sort_values(ascending=False).plot.bar(color= 'black')\n",
    "plt.title(\"Top 20 breeds with most tweets \",fontsize=18)\n",
    "plt.ylabel(\"Average tweets per each breed \")\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as u can see we have got golden_retriever first which means that this breed is popular among this community  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note .\n",
    "if i used the the most likes , retweets or score (rating) for each breed without taking their tweets count it wouldnt be accurate so i should take the avg per each breed / per each tweet  \n",
    "Example :  if we have 100000 likes for a breed with 106 tweets it would be 100000/106 = 943\n",
    "and for 50000 likes for a breed with 20 tweets 50000/20 = 2500 which mean that second breed has bigger mean per tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what about retweets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if i got each pack of breed tweets's retweets and divide it by the each breed tweets i will get the mean of every breed's tweet'retweets . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all_c.Dog_Breed.value_counts().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all_c['Retweets'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all_c.groupby('Dog_Breed')['Retweets'].sum().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_ret_per_breed = df_all_c.groupby('Dog_Breed')['Retweets'].mean().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c.groupby('Dog_Breed')['Retweets'].mean().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "num_of_ret_per_breed.nlargest(20).plot.bar(color= 'black')\n",
    "plt.title(\"Top 20 breeds with most retweets \",fontsize=18)\n",
    "plt.ylabel(\"Average retweets per breed \")\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bedlington_terrier in first place , now w've got golden_retriever as popularity among dog's ownsers in this community in that time era and Bedlington_terrier with  most avg retweets per breed ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which breed has most favourite? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c['Num_of_likes'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c.groupby('Dog_Breed')['Num_of_likes'].sum().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_fav_per_breed = df_all_c.groupby('Dog_Breed')['Num_of_likes'].mean().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c.groupby('Dog_Breed')['Num_of_likes'].mean().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "num_of_fav_per_breed.nlargest(20).plot.bar(color= 'black')\n",
    "plt.title(\"Top 20 breeds with most favourite per tweet \",fontsize=18)\n",
    "plt.ylabel(\"Average favourite per breed \")\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saluki in the first place , it becomes harder to get a decision about which better breed .\n",
    "### rating per each breed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c['Dog_score/10'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c.groupby('Dog_Breed')['Dog_score/10'].sum().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_per_breed = df_all_c.groupby('Dog_Breed')['Dog_score/10'].mean().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c.groupby('Dog_Breed')['Dog_score/10'].mean().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "avg_score_per_breed.nlargest(20).plot.barh(color= 'black')\n",
    "plt.title(\"Top 20 breeds with most rating per tweet \",fontsize=18)\n",
    "plt.ylabel(\"Average rating per breed \")\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i thought about a question that doesnt do anything with making decision about getting a dog \n",
    "and this que is, \n",
    "### which breed the machine recognized better ? \n",
    "60% to 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_c.groupby('Dog_Breed')['Probability_AI_calc'].mean().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_probability_per_breed=df_all_c.groupby('Dog_Breed')['Probability_AI_calc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "avg_probability_per_breed.nlargest(20).plot.bar(color= 'black')\n",
    "plt.title(\"Top 20 breeds with highest probability being recognized from the machine \",fontsize=18)\n",
    "plt.ylabel(\"Average probability per breed \")\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which dog had 100% recognized by the machine ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_all_c.query('Probability_AI_calc == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_all_c.query('Probability_AI_calc == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask.groupby('Dog_Breed')['Probability_AI_calc'].count().nlargest(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pug has got 8 times , this dog look is special "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is there a relation between favourite and retweet ? and what is that relation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "df_all_c.plot.scatter(x='Retweets',\n",
    "                      y='Num_of_likes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "its positive correlation and with some outliers  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "- udacity class room notes .\n",
    "- notes from my doctors in university and my colleagues.\n",
    "- https://pandas.pydata.org/\n",
    "- https://stackoverflow.com/\n",
    "- https://nfpdiscussions.udacity.com/   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
